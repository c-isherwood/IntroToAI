{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1. Suppose that the performance measure is concerned with just the first T \n",
    "   time steps of the environment and ignores everything thereafter. Show that \n",
    "   a rational agentâ€™s action may depend not just on the state of the environment \n",
    "   but also on the time step it has reached.\n",
    "\n",
    " In cases where the performance measure considers a finite number of steps, the rational action depends not only on the current state but also on the time step. This dependency arises because the remaining number of steps alters the set of possible future rewards. The agent must account for the temporal proximity to the end of the decision horizon to act rationally, optimizing its strategy based on both its current state and how much time it has left to achieve its goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2. Let us examine the rationality of various vacuum-cleaner agent functions.\n",
    "1. Show that the simple vacuum-cleaner agent function described in Figure 2.3 is indeed rational under the assumptions listed on page \n",
    "2. Describe a rational agent function for the case in which each movement costs one point. Does the corresponding agent program require internal state?\n",
    "The program must know the current state because it needs to know what is clean/if there is more to clean to optimize efficiency. A variable would be needed to measure the threshold of what should be cleaned. \n",
    "3. Discuss possible agent designs for the cases in which clean squares can become dirty and the geography of the environment is unknown. Does it make sense for the agent to learn from its experience in these cases? If so, what should it learn? If not, why not?\n",
    "The agent would need a loop to continue to explore. You want to minimize the number of movements still so learning the number of iterations before dirt comes back would be helpful. Learning the environment allows for better efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "''' Implement a performance-measuring environment simulator for the vacuum-cleaner world \n",
    "depicted in Figure 2.8 and specified on page . Your implementation should be modular so \n",
    "that the sensors, actuators, and environment characteristics (size, shape, dirt placement, \n",
    "etc.) can be changed easily. (Note: for some choices of programming language and operating \n",
    "system there are already implementations in the online code repository.) \n",
    "give the agent a score, every movement has a cost 1, suck cost 1, NoOp cost 0, clean a dirty patch gives 10, \n",
    "starts with 5. Implement reflex agents and a simple model agent, score both agents for all \n",
    "possible states ''' \n",
    "\n",
    "class Environment: \n",
    "    def __init__(self, size, dirt_locations): \n",
    "        self.size = size \n",
    "        self.dirt = set(dirt_locations)\n",
    "\n",
    "    def is_dirty(self, location): \n",
    "        return location in self.dirt \n",
    "\n",
    "    def remove_dirt(self, location): \n",
    "        if location in self.dirt: \n",
    "            self.dirt.remove(location)\n",
    "\n",
    "    def add_dirt(self, location): \n",
    "        self.dirt.add(location)\n",
    "\n",
    "class Agent: \n",
    "    def __init__(self, initial_score=5): \n",
    "        self.location = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflex Agent Score: 10\n",
      "Model Based Agent Score: 0\n"
     ]
    }
   ],
   "source": [
    "# simple agent code \n",
    "class Environment:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout  # layout is a dictionary with positions as keys and dirt status as values\n",
    "\n",
    "    def is_dirty(self, position):\n",
    "        return self.layout.get(position, False)\n",
    "\n",
    "    def clean(self, position):\n",
    "        if self.is_dirty(position):\n",
    "            self.layout[position] = False\n",
    "\n",
    "    def add_dirt(self, position):\n",
    "        self.layout[position] = True\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, environment):\n",
    "        self.environment = environment\n",
    "        self.position = 'A'  # initial position\n",
    "        self.score = 5       # initial score\n",
    "\n",
    "    def perceive(self):\n",
    "        return self.environment.is_dirty(self.position)\n",
    "\n",
    "    def move(self, target):\n",
    "        self.position = target\n",
    "        self.score -= 1\n",
    "\n",
    "    def suck(self):\n",
    "        if self.perceive():\n",
    "            self.environment.clean(self.position)\n",
    "            self.score += 9  # net gain of 10 for cleaning but -1 for the action\n",
    "\n",
    "    def no_op(self):\n",
    "        pass  # no operation, does nothing\n",
    "\n",
    "\n",
    "class ReflexAgent(Agent):\n",
    "    def choose_action(self):\n",
    "        if self.perceive():\n",
    "            self.suck()\n",
    "        else:\n",
    "            self.move('B' if self.position == 'A' else 'A')\n",
    "\n",
    "\n",
    "class ModelBasedAgent(Agent):\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "        self.model = {'A': False, 'B': False}  # Simplified model of the world\n",
    "\n",
    "    def update_model(self):\n",
    "        self.model[self.position] = self.perceive()\n",
    "\n",
    "    def choose_action(self):\n",
    "        self.update_model()\n",
    "        if self.model[self.position]:\n",
    "            self.suck()\n",
    "        else:\n",
    "            self.move('B' if self.position == 'A' else 'A')\n",
    "\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, agent, steps=10):\n",
    "        self.agent = agent\n",
    "        self.steps = steps\n",
    "\n",
    "    def run(self):\n",
    "        for _ in range(self.steps):\n",
    "            self.agent.choose_action()\n",
    "\n",
    "        return self.agent.score\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "environment = Environment({'A': True, 'B': False})\n",
    "reflex_agent = ReflexAgent(environment)\n",
    "model_agent = ModelBasedAgent(environment)\n",
    "\n",
    "simulation_reflex = Simulation(reflex_agent, 5)\n",
    "simulation_model = Simulation(model_agent, 5)\n",
    "\n",
    "print(\"Reflex Agent Score:\", simulation_reflex.run())\n",
    "print(\"Model Based Agent Score:\", simulation_model.run())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Dirt at A=False, Dirt at B=False, Initial Position=A -> Score: 4\n",
      "Config: Dirt at A=False, Dirt at B=False, Initial Position=B -> Score: 4\n",
      "Config: Dirt at A=False, Dirt at B=True, Initial Position=A -> Score: 13\n",
      "Config: Dirt at A=False, Dirt at B=True, Initial Position=B -> Score: 14\n",
      "Config: Dirt at A=True, Dirt at B=False, Initial Position=A -> Score: 14\n",
      "Config: Dirt at A=True, Dirt at B=False, Initial Position=B -> Score: 13\n",
      "Config: Dirt at A=True, Dirt at B=True, Initial Position=A -> Score: 22\n",
      "Config: Dirt at A=True, Dirt at B=True, Initial Position=B -> Score: 22\n",
      "Average Score: 13.25\n"
     ]
    }
   ],
   "source": [
    "# ex 12 \n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, dirt_a, dirt_b, initial_position):\n",
    "        self.positions = {'A': dirt_a, 'B': dirt_b}\n",
    "        self.agent_position = initial_position\n",
    "\n",
    "    def is_dirty(self):\n",
    "        return self.positions[self.agent_position]\n",
    "\n",
    "    def clean(self):\n",
    "        if self.is_dirty():\n",
    "            self.positions[self.agent_position] = False\n",
    "\n",
    "    def move(self):\n",
    "        self.agent_position = 'B' if self.agent_position == 'A' else 'A'\n",
    "\n",
    "\n",
    "class ReflexAgent:\n",
    "    def __init__(self, environment):\n",
    "        self.environment = environment\n",
    "        self.score = 5\n",
    "\n",
    "    def act(self):\n",
    "        if self.environment.is_dirty():\n",
    "            self.environment.clean()\n",
    "            self.score += 9  # 10 for cleaning, -1 for action\n",
    "        else:\n",
    "            self.environment.move()\n",
    "            self.score -= 1  # -1 for movement\n",
    "\n",
    "\n",
    "def simulate_environment(dirt_a, dirt_b, initial_position):\n",
    "    environment = Environment(dirt_a, dirt_b, initial_position)\n",
    "    agent = ReflexAgent(environment)\n",
    "    \n",
    "    # Run until no more dirt is present or a maximum of 4 actions to avoid infinite loops\n",
    "    for _ in range(4):\n",
    "        agent.act()\n",
    "        if not any(environment.positions.values()):\n",
    "            break\n",
    "    \n",
    "    return agent.score\n",
    "\n",
    "\n",
    "# Possible states are combinations of dirt at A and B and initial position\n",
    "dirt_configurations = [(False, False), (False, True), (True, False), (True, True)]\n",
    "initial_positions = ['A', 'B']\n",
    "results = {}\n",
    "\n",
    "for config in dirt_configurations:\n",
    "    for position in initial_positions:\n",
    "        score = simulate_environment(config[0], config[1], position)\n",
    "        results[(config, position)] = score\n",
    "\n",
    "# Calculate the average score\n",
    "average_score = sum(results.values()) / len(results)\n",
    "\n",
    "# Display results\n",
    "for k, v in results.items():\n",
    "    print(f\"Config: Dirt at A={k[0][0]}, Dirt at B={k[0][1]}, Initial Position={k[1]} -> Score: {v}\")\n",
    "\n",
    "print(\"Average Score:\", average_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 -1 -1 -1 -1 -1 -1\n",
      "-1 False True False True True -1\n",
      "-1 False False False True False -1\n",
      "-1 False False False False True -1\n",
      "-1 False False False True False -1\n",
      "-1 False True True True True -1\n",
      "-1 -1 -1 -1 -1 -1 -1\n",
      "Agent Position: (3, 3)\n",
      "Random Agent Score: -6\n",
      "-1 -1 -1 -1 -1 -1 -1\n",
      "-1 False False False False False -1\n",
      "-1 True False False False False -1\n",
      "-1 False False False False False -1\n",
      "-1 False False False False False -1\n",
      "-1 True False False False False -1\n",
      "-1 -1 -1 -1 -1 -1 -1\n",
      "Agent Position: (3, 5)\n",
      "Reflex Agent Score: 6\n",
      "-1 -1 -1 -1 -1 -1 -1\n",
      "-1 False False False False False -1\n",
      "-1 False False False False False -1\n",
      "-1 False False False False False -1\n",
      "-1 False False False False False -1\n",
      "-1 False False False False False -1\n",
      "-1 -1 -1 -1 -1 -1 -1\n",
      "Agent Position: (5, 5)\n",
      "Model-Based Agent Score: 107\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class GridEnvironment:\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n + 2  # account for walls\n",
    "        self.m = m + 2  # account for walls\n",
    "        # Initialize grid with walls (-1) around the periphery and random dirt or clean spaces inside\n",
    "        self.grid = [[-1 if i == 0 or i == n+1 or j == 0 or j == m+1 else random.choice([True, False]) \n",
    "                      for j in range(self.m)] for i in range(self.n)]\n",
    "        # Set the agent's initial position to [1, 1] (the first cell inside the wall)\n",
    "        self.agent_position = (1, 1)\n",
    "\n",
    "    def is_dirty(self, position):\n",
    "        x, y = position\n",
    "        return self.grid[x][y] if self.grid[x][y] != -1 else False\n",
    "\n",
    "    def clean(self, position):\n",
    "        if self.is_dirty(position):\n",
    "            self.grid[position[0]][position[1]] = False\n",
    "\n",
    "    def display(self):\n",
    "        for row in self.grid:\n",
    "            print(' '.join(str(x) for x in row))\n",
    "        print(f\"Agent Position: {self.agent_position}\")\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, environment):\n",
    "        self.environment = environment\n",
    "        self.score = 5\n",
    "\n",
    "    def move(self, direction):\n",
    "        x, y = self.environment.agent_position\n",
    "        if direction == 'up':\n",
    "            new_x = x - 1\n",
    "        elif direction == 'down':\n",
    "            new_x = x + 1\n",
    "        else:\n",
    "            new_x = x\n",
    "\n",
    "        if direction == 'left':\n",
    "            new_y = y - 1\n",
    "        elif direction == 'right':\n",
    "            new_y = y + 1\n",
    "        else:\n",
    "            new_y = y\n",
    "\n",
    "        # Check for walls before moving\n",
    "        if self.environment.grid[new_x][new_y] != -1:\n",
    "            self.environment.agent_position = (new_x, new_y)\n",
    "            self.score -= 1\n",
    "\n",
    "    def suck(self):\n",
    "        if self.environment.is_dirty(self.environment.agent_position):\n",
    "            self.environment.clean(self.environment.agent_position)\n",
    "            self.score += 9  # 10 for cleaning, -1 for the action\n",
    "\n",
    "    def no_op(self):\n",
    "        pass  # no operation, does nothing\n",
    "\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def act(self):\n",
    "        actions = ['up', 'down', 'left', 'right', 'suck', 'no_op']\n",
    "        action = random.choice(actions)\n",
    "        if action == 'suck':\n",
    "            self.suck()\n",
    "        elif action in ['up', 'down', 'left', 'right']:\n",
    "            self.move(action)\n",
    "        elif action == 'no_op':\n",
    "            self.no_op()\n",
    "\n",
    "\n",
    "class ReflexAgent(Agent):\n",
    "    def act(self):\n",
    "        if self.environment.is_dirty(self.environment.agent_position):\n",
    "            self.suck()\n",
    "        else:\n",
    "            direction = random.choice(['up', 'down', 'left', 'right'])\n",
    "            self.move(direction)\n",
    "\n",
    "\n",
    "class ModelBasedAgent(Agent):\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "        self.visited = set()\n",
    "        self.visited.add(environment.agent_position)\n",
    "\n",
    "    def act(self):\n",
    "        if self.environment.is_dirty(self.environment.agent_position):\n",
    "            self.suck()\n",
    "        else:\n",
    "            possible_moves = ['up', 'down', 'left', 'right']\n",
    "            best_move = None\n",
    "            x, y = self.environment.agent_position\n",
    "            for move in possible_moves:\n",
    "                new_pos = {\n",
    "                    'up': (x-1, y),\n",
    "                    'down': (x+1, y),\n",
    "                    'left': (x, y-1),\n",
    "                    'right': (x, y+1)\n",
    "                }[move]\n",
    "                if self.environment.grid[new_pos[0]][new_pos[1]] != -1 and new_pos not in self.visited:\n",
    "                    best_move = move\n",
    "                    break\n",
    "            if best_move:\n",
    "                self.move(best_move)\n",
    "                self.visited.add(self.environment.agent_position)\n",
    "            else:\n",
    "                self.no_op()  # No unvisited positions and no dirt, do nothing\n",
    "\n",
    "\n",
    "def run_simulation(agent_class, steps=100, n=5, m=5):\n",
    "    environment = GridEnvironment(n, m)\n",
    "    agent = agent_class(environment)\n",
    "    for _ in range(steps):\n",
    "        agent.act()\n",
    "    environment.display()\n",
    "    return agent.score\n",
    "\n",
    "# Running the simulations\n",
    "print(\"Random Agent Score:\", run_simulation(RandomAgent))\n",
    "print(\"Reflex Agent Score:\", run_simulation(ReflexAgent))\n",
    "print(\"Model-Based Agent Score:\", run_simulation(ModelBasedAgent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/matplotlib/_c_internal_utils.cpython-39-darwin.so, 0x0002): tried: '/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/matplotlib/_c_internal_utils.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have (arm64), need (x86_64)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Setup basic configuration for logging \u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/__init__.py:159\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/cbook.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _c_internal_utils\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_running_interactive_framework\u001b[39m():\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    Return the interactive framework whose event loop is currently running, if\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    any, or \"headless\" if no event loop can be started, or None.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m        \"macosx\", \"headless\", ``None``.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/matplotlib/_c_internal_utils.cpython-39-darwin.so, 0x0002): tried: '/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/matplotlib/_c_internal_utils.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have (arm64), need (x86_64)))"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "# Setup basic configuration for logging \n",
    "logging.basicConfig(filename='simulation_results.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class GridEnvironment:\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n + 2\n",
    "        self.m = m + 2\n",
    "        self.grid = [[-1 if i == 0 or i == n + 1 or j == 0 or j == m + 1 else random.choice([True, False])\n",
    "                      for j in range(self.m)] for i in range(self.n)]\n",
    "        self.agent_position = (1, 1)\n",
    "\n",
    "    def is_dirty(self, position):\n",
    "        x, y = position\n",
    "        return self.grid[x][y] if self.grid[x][y] != -1 else False\n",
    "\n",
    "    def clean(self, position):\n",
    "        if self.is_dirty(position):\n",
    "            self.grid[position[0]][position[1]] = False\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, environment):\n",
    "        self.environment = environment\n",
    "        self.score = 5\n",
    "\n",
    "    def move(self, direction):\n",
    "        x, y = self.environment.agent_position\n",
    "        if direction == 'up':\n",
    "            new_x = x - 1\n",
    "        elif direction == 'down':\n",
    "            new_x = x + 1\n",
    "        else:\n",
    "            new_x = x\n",
    "\n",
    "        if direction == 'left':\n",
    "            new_y = y - 1\n",
    "        elif direction == 'right':\n",
    "            new_y = y + 1\n",
    "        else:\n",
    "            new_y = y\n",
    "\n",
    "        if self.environment.grid[new_x][new_y] != -1:\n",
    "            self.environment.agent_position = (new_x, new_y)\n",
    "            self.score -= 1\n",
    "\n",
    "    def suck(self):\n",
    "        if self.environment.is_dirty(self.environment.agent_position):\n",
    "            self.environment.clean(self.environment.agent_position)\n",
    "            self.score += 9\n",
    "\n",
    "    def no_op(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def act(self):\n",
    "        actions = ['up', 'down', 'left', 'right', 'suck', 'no_op']\n",
    "        action = random.choice(actions)\n",
    "        if action == 'suck':\n",
    "            self.suck()\n",
    "        elif action in ['up', 'down', 'left', 'right']:\n",
    "            self.move(action)\n",
    "        elif action == 'no_op':\n",
    "            self.no_op()\n",
    "\n",
    "\n",
    "class ReflexAgent(Agent):\n",
    "    def act(self):\n",
    "        if self.environment.is_dirty(self.environment.agent_position):\n",
    "            self.suck()\n",
    "        else:\n",
    "            direction = random.choice(['up', 'down', 'left', 'right'])\n",
    "            self.move(direction)\n",
    "\n",
    "\n",
    "class ModelBasedAgent(Agent):\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "        self.visited = set()\n",
    "        self.visited.add(environment.agent_position)\n",
    "\n",
    "    def act(self):\n",
    "        if self.environment.is_dirty(self.environment.agent_position):\n",
    "            self.suck()\n",
    "        else:\n",
    "            possible_moves = ['up', 'down', 'left', 'right']\n",
    "            best_move = None\n",
    "            x, y = self.environment.agent_position\n",
    "            for move in possible_moves:\n",
    "                new_pos = {\n",
    "                    'up': (x - 1, y),\n",
    "                    'down': (x + 1, y),\n",
    "                    'left': (x, y - 1),\n",
    "                    'right': (x, y + 1)\n",
    "                }[move]\n",
    "                if self.environment.grid[new_pos[0]][new_pos[1]] != -1 and new_pos not in self.visited:\n",
    "                    best_move = move\n",
    "                    break\n",
    "            if best_move:\n",
    "                self.move(best_move)\n",
    "                self.visited.add(self.environment.agent_position)\n",
    "            else:\n",
    "                self.no_op()\n",
    "\n",
    "\n",
    "def run_simulation(agent_class, steps=100, n=5, m=5):\n",
    "    scores = []\n",
    "    for _ in range(100):  # run 100 simulations for each agent\n",
    "        environment = GridEnvironment(n, m)\n",
    "        agent = agent_class(environment)\n",
    "        for __ in range(steps):\n",
    "            agent.act()\n",
    "        scores.append(agent.score)\n",
    "    average_score = mean(scores)\n",
    "    logging.info(f\"{agent_class.__name__} - Average Score: {average_score}\")\n",
    "    return scores, average_score\n",
    "\n",
    "# Running simulations for each agent\n",
    "agents = [RandomAgent, ReflexAgent, ModelBasedAgent]\n",
    "results = {}\n",
    "for agent in agents:\n",
    "    scores, avg_score = run_simulation(agent)\n",
    "    results[agent.__name__] = scores\n",
    "    print(f\"{agent.__name__} - Average Score: {avg_score}\")\n",
    "\n",
    "# Plotting the scores using box plots\n",
    "fig, ax = plt.subplots()\n",
    "score_lists = [results[agent.__name__] for agent in agents]\n",
    "ax.boxplot(score_lists, vert=True, patch_artist=True, labels=[agent.__name__ for agent in agents])\n",
    "ax.set_title('Box Plot of Scores for Each Agent')\n",
    "ax.set_xlabel('Agent Type')\n",
    "ax.set_ylabel('Scores')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/PIL/_imaging.cpython-39-darwin.so, 0x0002): tried: '/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/PIL/_imaging.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have (arm64), need (x86_64)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_multiple_simulations\u001b[39m(agent_class, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/__init__.py:159\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/rcsetup.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/colors.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Real\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPngImagePlugin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:97\u001b[0m\n\u001b[1;32m     88\u001b[0m MAX_IMAGE_PIXELS: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    100\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/PIL/_imaging.cpython-39-darwin.so, 0x0002): tried: '/Users/campbellisherwood/Library/Python/3.9/lib/python/site-packages/PIL/_imaging.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have (arm64), need (x86_64)))"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def run_multiple_simulations(agent_class, num_runs=30, steps=100, n=5, m=5):\n",
    "    scores = []\n",
    "    for _ in range(num_runs):\n",
    "        environment = GridEnvironment(n, m)\n",
    "        agent = agent_class(environment)\n",
    "        for _ in range(steps):\n",
    "            agent.act()\n",
    "        scores.append(agent.score)\n",
    "    return scores\n",
    "\n",
    "# Example agents to include in the simulation\n",
    "agents = [RandomAgent, ReflexAgent]\n",
    "\n",
    "# Collect data\n",
    "data = {agent.__name__: run_multiple_simulations(agent) for agent in agents}\n",
    "\n",
    "# Plotting the data\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data.values(), labels=data.keys())\n",
    "ax.set_title('Performance Comparison of Different Agents')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Agent Type')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
